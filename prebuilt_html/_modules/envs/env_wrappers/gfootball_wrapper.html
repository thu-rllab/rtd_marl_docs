<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>envs.env_wrappers.gfootball_wrapper &mdash; Distributed Multi-agent Reinforcement Learning v0.1 documentation</title>
      <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/marl.css" type="text/css" />
      <link rel="stylesheet" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/sphinx_highlight.js"></script>
        <script src="../../../_static/clipboard.min.js"></script>
        <script src="../../../_static/copybutton.js"></script>
        <script src="../../../_static/design-tabs.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            Distributed Multi-agent Reinforcement Learning
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/get_started.html">Get Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/installation.html">Installation Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/logging_instructions.html">Logging Instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../tutorials/environment_design.html">How to Integrate a Multi-agent Environment into dist-MARL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Development Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../develop_docs/develop_instructions.html">dist-MARL 开发指南</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../develop_docs/modify_rpc.html">dist-MARL 的分布式框架介绍</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Internal Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../internal_docs/common/common_modules.html">Common</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api_docs/common/modules.html">common</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_docs/envs/modules.html">envs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Distributed Multi-agent Reinforcement Learning</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">envs.env_wrappers.gfootball_wrapper</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for envs.env_wrappers.gfootball_wrapper</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Iterator</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">NoReturn</span>

<span class="kn">import</span> <span class="nn">gfootball.env</span> <span class="k">as</span> <span class="nn">football_env</span>

<span class="kn">from</span> <span class="nn">envs</span> <span class="kn">import</span> <span class="n">MultiAgentEnvBase</span>


<div class="viewcode-block" id="GoogleFootballEnv"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv">[docs]</a><span class="k">class</span> <span class="nc">GoogleFootballEnv</span><span class="p">(</span><span class="n">MultiAgentEnvBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Google Research Football environment wrapper.</span>
<span class="sd">    </span>
<span class="sd">    Attributes:</span>
<span class="sd">        env (gfootball.env.football_env.FootballEnv): The Google Research Football Environment instance.</span>
<span class="sd">        episode_limit (int): The maximum steps of a single episode, and reaching it will lead to ``terminated=True``.</span>
<span class="sd">        map_name (str): The name of the map.</span>
<span class="sd">        _action_spaces (list[gym.spaces.Discrete]): action spaces of all agents, private.</span>
<span class="sd">        _n_agents (int): The number of players controlled by the RL agents, private.</span>
<span class="sd">        _obs (np.ndarray): The current observation, shape: [_n_agents, obs_size], private.</span>
<span class="sd">        _observation_spaces (list[gym.spaces.Box]): observation spaces of all agents, private.</span>
<span class="sd">        _seed (int): The random seed for the environment, private variable, private.</span>
<span class="sd">        _time_step (int): The timestep, will be reset to 0 at the beginning of every episode, private.</span>
<span class="sd">    &quot;&quot;&quot;</span>    
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_agents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">episode_limit</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
        <span class="n">map_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;academy_3_vs_1_with_keeper&quot;</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize a GRF instance with ``map_name`` given.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            n_agents (int, optional): The number of players controlled by the RL agents, corresponding to arg ``number_of_left_players_agent_controls`` in the GRF environment class, defaults to 3.</span>
<span class="sd">            episode_limit (int, optional): The maximum steps of a single episode, and reaching it will lead to ``terminated=True``, defaults to 200.</span>
<span class="sd">            map_name (str, optional): The name of the environment map, defaults to &quot;academy_3_vs_1_with_keeper&quot;.</span>
<span class="sd">            seed (int, optional): The random seed, defaults to ``None`` and the environment will generate a random integer in [1e6, 1e7] as ``self._seed``.</span>
<span class="sd">            **kwargs: keyword arguments for Google Research Football.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">map_name</span> <span class="o">=</span> <span class="n">map_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_agents</span> <span class="o">=</span> <span class="n">n_agents</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">episode_limit</span> <span class="o">=</span> <span class="n">episode_limit</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">=</span> <span class="n">seed</span> <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mf">1e6</span><span class="p">,</span> <span class="mf">1e7</span><span class="p">)</span>

        <span class="c1"># create the environment instance</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span> <span class="o">=</span> <span class="n">football_env</span><span class="o">.</span><span class="n">create_environment</span><span class="p">(</span>
            <span class="n">env_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_name</span><span class="p">,</span>
            <span class="n">number_of_left_players_agent_controls</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_agents</span><span class="p">,</span>
            <span class="n">channel_dimensions</span><span class="o">=</span><span class="p">(</span><span class="n">football_env</span><span class="o">.</span><span class="n">observation_preprocessing</span><span class="o">.</span><span class="n">SMM_WIDTH</span><span class="p">,</span> <span class="n">football_env</span><span class="o">.</span><span class="n">observation_preprocessing</span><span class="o">.</span><span class="n">SMM_HEIGHT</span><span class="p">),</span>
            <span class="o">**</span><span class="n">kwargs</span>
        <span class="p">)</span>
        <span class="c1"># set the random seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">()</span>
        
        <span class="c1"># set the action space and observation space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_action_spaces</span> <span class="o">=</span> <span class="p">[</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">nvec</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_agents</span><span class="p">)]</span>
        
        <span class="n">obs_space_low</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">low</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">obs_space_high</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">high</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_observation_spaces</span> <span class="o">=</span> <span class="p">[</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">obs_space_low</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">obs_space_high</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_agents</span><span class="p">)]</span>

        <span class="c1"># init other variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_obs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_time_step</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Obtain the total number of actions an agent could ever take.</span>

<span class="sd">        Note:</span>
<span class="sd">            This is only suitable for a discrete 1 dimensional action space for each agent.</span>
<span class="sd">            You are recommended to use ``GoogleFootballEnv().action_space``.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: **n_actions**: The total number of actions an agent can ever take.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">action_spaces</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">n</span><span class="p">)</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">n_agents</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Obtain the number of the agents in this environment.</span>

<span class="sd">        Returns:</span>
<span class="sd">            int: **n_agents**: The number of the left players controlled by RL agents.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_agents</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">action_spaces</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Discrete</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the action space of the environment.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            List[gym.spaces.Discrete]: **action_space**: The action space of the environment.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_action_spaces</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">observation_spaces</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">gym</span><span class="o">.</span><span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Get the observation space of the environment.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            List[gym.spaces.Box]: **action_space**: The observation space of the environment.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_observation_spaces</span>

<div class="viewcode-block" id="GoogleFootballEnv._checkTermination"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv._checkTermination">[docs]</a>    <span class="k">def</span> <span class="nf">_checkTermination</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Check if the episode is terminated. This method might be overwritted by different maps or tasks.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            bool: **terminated**: Whether the episode has ended.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># when the timestep reaches the episode_limit, terminate the episode</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_time_step</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">episode_limit</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        
        <span class="k">return</span> <span class="kc">False</span></div>
    
<div class="viewcode-block" id="GoogleFootballEnv.close"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.close">[docs]</a>    <span class="k">def</span> <span class="nf">close</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Override close in your subclass to perform any necessary cleanup.</span>

<span class="sd">        Environments will automatically close() themselves when garbage collected or when the program exists.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>
    
<div class="viewcode-block" id="GoogleFootballEnv.getAvailActions"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.getAvailActions">[docs]</a>    <span class="k">def</span> <span class="nf">getAvailActions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Obtain the available actions of all agents in a list. Note that all actions are available in GRF at anytime.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list[np.ndarray]: **avail_actions**: A list of available actions for all agents.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">agent_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_agents</span><span class="p">)]</span></div>
    
<div class="viewcode-block" id="GoogleFootballEnv.getAvailActionsAgent"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.getAvailActionsAgent">[docs]</a>    <span class="k">def</span> <span class="nf">getAvailActionsAgent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Obtain the available actions for a specific agent given the agent_id. Note that all actions are available in GRF at anytime.</span>
<span class="sd">        </span>
<span class="sd">        Args:</span>
<span class="sd">            agent_id (int): The ID for the specific agent.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: **avail_agent_actions**: The actions that the agent with the given id can take at the current state.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_actions</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="GoogleFootballEnv.getEnvInfo"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.getEnvInfo">[docs]</a>    <span class="k">def</span> <span class="nf">getEnvInfo</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Obtain the environment information in a Dict.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            DeprecationWarning: keys ``state_shape`` and ``obs_shape`` will be deprecated soon! Please use ``state_size`` and ``obs_size`` instead.</span>

<span class="sd">        Returns:</span>
<span class="sd">            dict: **env_info_dict**: The environment information, which contains ``n_actions, n_agents, episode_limit, obs_size, state_size, step_info``.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">env_info_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;state_shape&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">getStateShape</span><span class="p">()</span><span class="o">.</span><span class="n">prod</span><span class="p">()),</span>
            <span class="s2">&quot;obs_shape&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">getObsShape</span><span class="p">()</span><span class="o">.</span><span class="n">prod</span><span class="p">()),</span>
            <span class="s2">&quot;state_size&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">getStateShape</span><span class="p">()</span><span class="o">.</span><span class="n">prod</span><span class="p">()),</span>
            <span class="s2">&quot;obs_size&quot;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">getObsShape</span><span class="p">()</span><span class="o">.</span><span class="n">prod</span><span class="p">()),</span>
            <span class="s2">&quot;n_actions&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_actions</span><span class="p">,</span>
            <span class="s2">&quot;n_agents&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_agents</span><span class="p">,</span>
            <span class="s2">&quot;episode_limit&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">episode_limit</span><span class="p">,</span>
            <span class="s2">&quot;step_info&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;score_reward&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
        <span class="p">}</span>
        
        <span class="k">return</span> <span class="n">env_info_dict</span></div>
    
<div class="viewcode-block" id="GoogleFootballEnv.getObs"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.getObs">[docs]</a>    <span class="k">def</span> <span class="nf">getObs</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Obtain all agents&#39; observations in a list.</span>

<span class="sd">        Returns:</span>
<span class="sd">            list[np.ndarray]: **observations**: The list of observations for all agents.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_obs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_agents</span><span class="p">)]</span></div>

<div class="viewcode-block" id="GoogleFootballEnv.getObsAgent"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.getObsAgent">[docs]</a>    <span class="k">def</span> <span class="nf">getObsAgent</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">agent_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Obtain the observation for a specific agent given the agent_id.</span>

<span class="sd">        Args:</span>
<span class="sd">            agent_id (int): The ID for the specific agent.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: **observation**: The observation for the agent.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_obs</span><span class="p">[</span><span class="n">agent_id</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span></div>
    
<div class="viewcode-block" id="GoogleFootballEnv.getObsShape"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.getObsShape">[docs]</a>    <span class="k">def</span> <span class="nf">getObsShape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Obtain the shape of the observation.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: **obs_shape**: The shape of the observation.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">obs_shape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">observation_spaces</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">obs_shape</span></div>
    
<div class="viewcode-block" id="GoogleFootballEnv.getState"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.getState">[docs]</a>    <span class="k">def</span> <span class="nf">getState</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Obtain the global state.</span>

<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: **state**: The global state for all agents.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_obs</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span></div>

<div class="viewcode-block" id="GoogleFootballEnv.getStateShape"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.getStateShape">[docs]</a>    <span class="k">def</span> <span class="nf">getStateShape</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Obtain the shape of the state.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            np.ndarray: **state_shape**: The shape of the state.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getObsShape</span><span class="p">()</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_agents</span></div>
    
<div class="viewcode-block" id="GoogleFootballEnv.reset"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.reset">[docs]</a>    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reset the state of the environment and return the initial observations.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (list[np.ndarray], np.ndarray): **(observations, state)**: (The initial observations, The global state for all agents)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_obs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_time_step</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getObs</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">getState</span><span class="p">()</span></div>
    
<div class="viewcode-block" id="GoogleFootballEnv.sampleActions"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.sampleActions">[docs]</a>    <span class="k">def</span> <span class="nf">sampleActions</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sample random actions.</span>
<span class="sd">        </span>
<span class="sd">        Return:</span>
<span class="sd">            list[int]: **random_actions**: The sampled random actions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span> <span class="k">for</span> <span class="n">action_space</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_spaces</span><span class="p">]</span></div>

<div class="viewcode-block" id="GoogleFootballEnv.seed"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.seed">[docs]</a>    <span class="k">def</span> <span class="nf">seed</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">NoReturn</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the random seed for this GRF environment instance. If ``seed==None``, then a random integer in [1e6, 1e7] will be used.</span>

<span class="sd">        Args:</span>
<span class="sd">            seed (int, optional): The random seed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_seed</span> <span class="o">=</span> <span class="n">seed</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_seed</span><span class="p">)</span></div>
        
<div class="viewcode-block" id="GoogleFootballEnv.step"><a class="viewcode-back" href="../../../api_docs/envs/envs.env_wrappers.html#envs.env_wrappers.gfootball_wrapper.GoogleFootballEnv.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actions</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">list</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one timestep of the environment&#39;s dynamics. When the end of episode is reached, you are responsible for</span>
<span class="sd">        calling func ``reset()`` to reset this environment&#39;s state.</span>

<span class="sd">        Accepts the actions and returns a tuple (observations, reward, terminated, info), where:</span>

<span class="sd">        - **observations**: A list of agents&#39; observations of the current state.</span>
<span class="sd">        - **reward**: Amount of reward returned after previous actions.</span>
<span class="sd">        - **terminated (a.k.a. done)**: Whether the episode has ended, in which case further ``step()`` calls will return undefined results.</span>
<span class="sd">        - **info**: Contains auxiliary diagnostic information (helpful for debugging, and sometimes learning).</span>

<span class="sd">        Args:</span>
<span class="sd">            actions (np.ndarray or list): Actions taken by the agents.</span>
<span class="sd">        </span>
<span class="sd">        Returns:</span>
<span class="sd">            (list[np.ndarray], float, bool, dict): **(observations, reward, terminated, info)**</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_time_step</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">observations</span><span class="p">,</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">actions</span><span class="p">))</span>
        
        <span class="c1"># update variables</span>
        <span class="n">sum_reward</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">rewards</span><span class="p">)</span>
        <span class="n">terminated</span> <span class="o">=</span> <span class="n">terminated</span> <span class="o">|</span> <span class="bp">self</span><span class="o">.</span><span class="n">_checkTermination</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_obs</span> <span class="o">=</span> <span class="n">observations</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">getObs</span><span class="p">(),</span> <span class="n">sum_reward</span><span class="p">,</span> <span class="n">terminated</span><span class="p">,</span> <span class="n">info</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, thu-rllab.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>